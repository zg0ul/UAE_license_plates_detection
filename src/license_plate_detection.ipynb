{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59df497a",
   "metadata": {},
   "source": [
    "# Dubai License Plate Detection\n",
    "\n",
    "This notebook demonstrates different approaches for detecting and recognizing Dubai license plates using YOLOv9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff454c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added YOLOv9 path: /Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9\n",
      "Added src path: /Users/zg0ul/Coding/SAGER/dubai_license\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 8]  # Set default figure size\n",
    "\n",
    "# Add the yolov9 directory to Python path\n",
    "# This is crucial for importing the YOLOv9 modules correctly\n",
    "yolov9_path = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), \"yolov9\"))\n",
    "if not os.path.exists(yolov9_path):\n",
    "    yolov9_path = os.path.abspath(os.path.join(os.getcwd(), \"yolov9\"))\n",
    "\n",
    "if yolov9_path not in sys.path:\n",
    "    sys.path.insert(0, yolov9_path)\n",
    "    print(f\"Added YOLOv9 path: {yolov9_path}\")\n",
    "\n",
    "# Now we can import YOLOv9 modules\n",
    "from yolov9.models.common import DetectMultiBackend\n",
    "from yolov9.utils.dataloaders import LoadImages\n",
    "from yolov9.utils.general import non_max_suppression, scale_boxes\n",
    "from yolov9.utils.plots import Annotator, colors\n",
    "\n",
    "# Add the src directory to Python path if it's not already there\n",
    "src_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added src path: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b3fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the extract_license_info function\n",
    "def extract_license_info(detections):\n",
    "    \"\"\"Extract emirate, category, and license number from license plate detections\"\"\"\n",
    "    if not detections:\n",
    "        return {'emirate': 'Unknown', 'category': 'Unknown', 'plate_number': 'Unknown'}\n",
    "\n",
    "    # Convert detections to a more convenient format\n",
    "    elements = []\n",
    "    for detection in detections:\n",
    "        if isinstance(detection, dict) and 'bbox' in detection:\n",
    "            # If detection is already in dictionary format\n",
    "            x1, y1, x2, y2 = detection['bbox']\n",
    "            cls = detection['class']\n",
    "            conf = detection['confidence']\n",
    "        else:\n",
    "            # If detection is in the format from your output\n",
    "            cls = detection[0]\n",
    "            conf = detection[1]\n",
    "            x1, y1, x2, y2 = map(int, detection[2].strip('()').split(','))\n",
    "\n",
    "        center_x = (x1 + x2) / 2\n",
    "        center_y = (y1 + y2) / 2\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        area = width * height\n",
    "\n",
    "        elements.append({\n",
    "            'class': cls,\n",
    "            'confidence': conf,\n",
    "            'bbox': (x1, y1, x2, y2),\n",
    "            'center': (center_x, center_y),\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'area': area\n",
    "        })\n",
    "\n",
    "    # First identify the plate itself if it's in the detections\n",
    "    plate_elements = [e for e in elements if 'plate' in str(e['class']).lower()]\n",
    "    plate_bbox = None\n",
    "    if plate_elements:\n",
    "        # Use the largest plate detection\n",
    "        plate_elements.sort(key=lambda x: x['area'], reverse=True)\n",
    "        plate_bbox = plate_elements[0]['bbox']\n",
    "        # Remove plate from further processing\n",
    "        elements = [e for e in elements if e not in plate_elements]\n",
    "\n",
    "    # Identify emirate - typically contains \"DUBAI\" in the class name\n",
    "    emirate_elements = [e for e in elements if any(em in str(e['class']).upper() \n",
    "                        for em in ['DUBAI', 'AJMAN', 'SHARKA', 'ABUDABI', 'FUJIRA', 'RAK', 'AM'])]\n",
    "    emirate = emirate_elements[0]['class'] if emirate_elements else 'Unknown'\n",
    "\n",
    "    # Remove emirate from further processing\n",
    "    if emirate_elements:\n",
    "        for e in emirate_elements:\n",
    "            if e in elements:  # Check if element is still in the list\n",
    "                elements.remove(e)\n",
    "\n",
    "    # If no elements left after removing emirate, return early\n",
    "    if not elements:\n",
    "        return {\n",
    "            'emirate': emirate,\n",
    "            'category': 'Unknown',\n",
    "            'plate_number': 'Unknown'\n",
    "        }\n",
    "\n",
    "    # Group elements by their vertical position (y-coordinate)\n",
    "    y_values = [e['center'][1] for e in elements]\n",
    "    min_y, max_y = min(y_values), max(y_values)\n",
    "    vertical_range = max_y - min_y\n",
    "\n",
    "    # Check for known category letters common in UAE plates\n",
    "    known_categories = set(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "                           'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Z'])\n",
    "    \n",
    "    # Look for known category letters first\n",
    "    category_candidates = [e for e in elements if str(e['class']).upper() in known_categories]\n",
    "    \n",
    "    if category_candidates:\n",
    "        # Found explicit category\n",
    "        category_elements = [category_candidates[0]]  # Use the first detected category\n",
    "        number_elements = [e for e in elements if e not in category_elements]\n",
    "        # Sort number elements by x-coordinate\n",
    "        number_elements.sort(key=lambda e: e['center'][0])\n",
    "    else:\n",
    "        # No explicit category detected - handle rows and positioning\n",
    "        if vertical_range > 20:  # Threshold for multiple rows\n",
    "            # Group elements by vertical position\n",
    "            median_y = sum(y_values) / len(y_values)\n",
    "\n",
    "            upper_row = [e for e in elements if e['center'][1] < median_y]\n",
    "            lower_row = [e for e in elements if e['center'][1] >= median_y]\n",
    "\n",
    "            # Sort each row by x-coordinate\n",
    "            upper_row.sort(key=lambda e: e['center'][0])\n",
    "            lower_row.sort(key=lambda e: e['center'][0])\n",
    "\n",
    "            # For Dubai plates, typically upper row is category and lower row is number\n",
    "            if len(upper_row) < len(lower_row) and len(upper_row) <= 2:\n",
    "                if any(str(e['class']).isalpha() for e in upper_row):\n",
    "                    category_elements = upper_row\n",
    "                    number_elements = lower_row\n",
    "                else:\n",
    "                    # Upper row doesn't look like a category - mark as unknown\n",
    "                    category_elements = []\n",
    "                    number_elements = elements\n",
    "                    number_elements.sort(key=lambda e: e['center'][0])\n",
    "            else:\n",
    "                # Look for alphabetic characters that could indicate category\n",
    "                alpha_elements = [e for e in elements if isinstance(e['class'], str) and e['class'].isalpha()]\n",
    "                if alpha_elements:\n",
    "                    # Find the leftmost alphabetic element\n",
    "                    alpha_elements.sort(key=lambda e: e['center'][0])\n",
    "                    category_elements = [alpha_elements[0]]\n",
    "                    number_elements = [e for e in elements if e not in category_elements]\n",
    "                    number_elements.sort(key=lambda e: e['center'][0])\n",
    "                else:\n",
    "                    # Don't default to first element as category if it's not alphabetic\n",
    "                    category_elements = []\n",
    "                    number_elements = elements\n",
    "                    number_elements.sort(key=lambda e: e['center'][0])\n",
    "        else:\n",
    "            # Single row plate - sort horizontally\n",
    "            elements.sort(key=lambda e: e['center'][0])\n",
    "\n",
    "            # Check if first element is a valid alphabetic category\n",
    "            if elements and isinstance(elements[0]['class'], str) and elements[0]['class'].upper() in known_categories:\n",
    "                category_elements = [elements[0]]\n",
    "                number_elements = elements[1:]\n",
    "            else:\n",
    "                # Check for gaps between elements\n",
    "                gaps = []\n",
    "                gap_indices = []\n",
    "                for i in range(1, len(elements)):\n",
    "                    gap = elements[i]['center'][0] - elements[i-1]['center'][0]\n",
    "                    gaps.append(gap)\n",
    "                    gap_indices.append(i-1)\n",
    "\n",
    "                if gaps:\n",
    "                    avg_gap = sum(gaps) / len(gaps)\n",
    "                    significant_gap_indices = [i for i, g in zip(gap_indices, gaps) if g > 1.5 * avg_gap]\n",
    "\n",
    "                    if significant_gap_indices:\n",
    "                        # Use the most significant gap to split category and number\n",
    "                        max_gap_idx = max(significant_gap_indices, key=lambda i: gaps[i])\n",
    "                        left_elements = elements[:max_gap_idx+1]\n",
    "                        right_elements = elements[max_gap_idx+1:]\n",
    "                        \n",
    "                        # Only use left elements as category if they're alphabetic\n",
    "                        if all(isinstance(e['class'], str) and e['class'].isalpha() for e in left_elements):\n",
    "                            category_elements = left_elements\n",
    "                            number_elements = right_elements\n",
    "                        else:\n",
    "                            # Left elements don't look like a category\n",
    "                            category_elements = []\n",
    "                            number_elements = elements\n",
    "                    else:\n",
    "                        # Check for leftmost element being alphabetic (common for category)\n",
    "                        if isinstance(elements[0]['class'], str) and elements[0]['class'].isalpha():\n",
    "                            category_elements = [elements[0]]\n",
    "                            number_elements = elements[1:]\n",
    "                        else:\n",
    "                            category_elements = []\n",
    "                            number_elements = elements\n",
    "                else:\n",
    "                    # Only use first element as category if it's alphabetic\n",
    "                    if elements and isinstance(elements[0]['class'], str) and elements[0]['class'].isalpha():\n",
    "                        category_elements = [elements[0]]\n",
    "                        number_elements = elements[1:] if len(elements) > 1 else []\n",
    "                    else:\n",
    "                        category_elements = []\n",
    "                        number_elements = elements\n",
    "\n",
    "    # Extract category and plate number as strings\n",
    "    if category_elements:\n",
    "        category = ''.join([str(e['class']) for e in category_elements])\n",
    "    else:\n",
    "        category = 'Unknown'\n",
    "    \n",
    "    plate_number = ''.join([str(e['class']) for e in number_elements])\n",
    "\n",
    "    # Post-processing\n",
    "    if category == 'Unknown' and len(plate_number) > 3:\n",
    "        # Try to find category letters at the beginning\n",
    "        for i, char in enumerate(plate_number):\n",
    "            if char.upper() in known_categories:\n",
    "                # This might be a category letter\n",
    "                if i == 0:  # If it's the first character\n",
    "                    category = plate_number[0]\n",
    "                    plate_number = plate_number[1:]\n",
    "                    break\n",
    "\n",
    "    return {\n",
    "        'emirate': emirate,\n",
    "        'category': category,\n",
    "        'plate_number': plate_number\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13202dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_license_plate_image(image_path, model, conf_threshold=0.25, iou_threshold=0.45, img_size=640, save_output=False):\n",
    "    \"\"\"Process a license plate image: detect objects, extract license info, and visualize results\"\"\"\n",
    "    # Load and process image\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Check if the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image path '{image_path}' does not exist\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        dataset = LoadImages(image_path, img_size=img_size)\n",
    "\n",
    "        all_detections = []\n",
    "        license_info = None\n",
    "        result_img = None\n",
    "        original_img = None\n",
    "\n",
    "        for path, img, img_original, _, _ in dataset:\n",
    "            # Store original image\n",
    "            original_img = img_original.copy()\n",
    "\n",
    "            # Run inference\n",
    "            img = torch.tensor(img).to(model.device).float() / 255.0\n",
    "            if img.ndimension() == 3:\n",
    "                img = img.unsqueeze(0)\n",
    "\n",
    "            # Get predictions\n",
    "            pred = non_max_suppression(model(img), conf_threshold, iou_threshold)\n",
    "\n",
    "            # Process detections\n",
    "            annotator = Annotator(img_original.copy())\n",
    "\n",
    "            if pred[0] is not None and len(pred[0]) > 0:\n",
    "                detections = pred[0]\n",
    "                # Scale boxes to original image dimensions\n",
    "                detections[:, :4] = scale_boxes(img.shape[2:], detections[:, :4], img_original.shape).round()\n",
    "\n",
    "                # Process each detection\n",
    "                for *xyxy, conf, cls_id in detections:\n",
    "                    cls_id = int(cls_id)\n",
    "                    cls_name = model.names[cls_id] if cls_id < len(model.names) else f\"Class {cls_id}\"\n",
    "                    confidence = float(conf)\n",
    "                    bbox = [int(x) for x in xyxy]\n",
    "\n",
    "                    # Add detection to list\n",
    "                    all_detections.append({\n",
    "                        'class': cls_name,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': bbox\n",
    "                    })\n",
    "\n",
    "                    # Draw box on image\n",
    "                    label = f\"{cls_name} {confidence:.2f}\"\n",
    "                    annotator.box_label(xyxy, label, colors(cls_id, True))\n",
    "\n",
    "            # Extract license information\n",
    "            license_info = extract_license_info(all_detections)\n",
    "\n",
    "            # Get the annotated image\n",
    "            result_img = annotator.result()\n",
    "\n",
    "            # Save output if requested (now disabled by default)\n",
    "            if save_output:\n",
    "                output_dir = 'outputs'\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                file_name = Path(path).stem\n",
    "                output_path = os.path.join(output_dir, f\"license_info_{file_name}.jpg\")\n",
    "                cv2.imwrite(output_path, result_img)\n",
    "                print(f\"Saved result to {output_path}\")\n",
    "\n",
    "            # Break after first image (in case of video input)\n",
    "            break\n",
    "\n",
    "        # Calculate processing time\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        return {\n",
    "            'license_info': license_info,\n",
    "            'original_img': original_img,\n",
    "            'result_img': result_img,\n",
    "            'detections': all_detections,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5861edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_license_plates_batch(model, test_dir, num_images=5, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"Process multiple license plate images and display results\"\"\"\n",
    "    # Ensure test directory exists\n",
    "    if not os.path.exists(test_dir):\n",
    "        print(f\"Error: Test directory '{test_dir}' does not exist\")\n",
    "        return None\n",
    "\n",
    "    # Get list of image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(list(Path(test_dir).glob(f'*{ext}')))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {test_dir}\")\n",
    "        return None\n",
    "\n",
    "    # Select random images or all if fewer than requested\n",
    "    import random\n",
    "    if len(image_files) > num_images:\n",
    "        selected_images = random.sample(image_files, num_images)\n",
    "    else:\n",
    "        selected_images = image_files\n",
    "\n",
    "    print(f\"Processing {len(selected_images)} images from {test_dir}\")\n",
    "\n",
    "    # Process each image\n",
    "    results = []\n",
    "    for img_path in selected_images:\n",
    "        print(f\"\\nProcessing image: {img_path.name}\")\n",
    "        result = process_license_plate_image(\n",
    "            str(img_path), model, conf_threshold, iou_threshold, save_output=False)\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"Failed to process image: {img_path.name}\")\n",
    "            continue\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "        # Display original and processed images side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "        # Original image\n",
    "        orig_img_rgb = cv2.cvtColor(result['original_img'], cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(orig_img_rgb)\n",
    "        ax1.set_title(\"Original Image\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        # Annotated image with detections\n",
    "        result_img_rgb = cv2.cvtColor(result['result_img'], cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(result_img_rgb)\n",
    "        ax2.set_title(\"Detected Objects\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"License Plate: {img_path.name}\", fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "        # Display extracted license info directly under the images\n",
    "        license_info = result['license_info']\n",
    "        print(\"License Plate Information:\")\n",
    "        print(f\"Emirate: {license_info['emirate']}\")\n",
    "        print(f\"Category: {license_info['category']}\")\n",
    "        print(f\"License Number: {license_info['plate_number']}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_two_stage_detection(image_path, model, conf_threshold=0.25, iou_threshold=0.45, img_size=640):\n",
    "    \"\"\"Two-stage license plate detection approach\"\"\"\n",
    "    import tempfile\n",
    "    \n",
    "    # Stage 1: Detect the license plate\n",
    "    print(\"Stage 1: Detecting license plate...\")\n",
    "    dataset = LoadImages(image_path, img_size=img_size)\n",
    "    \n",
    "    # Load the original image\n",
    "    for path, img, img_original, _, _ in dataset:\n",
    "        original_img = img_original.copy()\n",
    "        break\n",
    "    \n",
    "    # Run first stage detection (focus on finding the plate)\n",
    "    plates = []\n",
    "    img = torch.tensor(img).to(model.device).float() / 255.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    \n",
    "    pred = non_max_suppression(model(img), conf_threshold, iou_threshold)\n",
    "    \n",
    "    # Process detections to find license plates\n",
    "    annotator_original = Annotator(original_img.copy())\n",
    "    \n",
    "    if pred[0] is not None and len(pred[0]) > 0:\n",
    "        detections = pred[0]\n",
    "        detections[:, :4] = scale_boxes(img.shape[2:], detections[:, :4], original_img.shape).round()\n",
    "        \n",
    "        for *xyxy, conf, cls_id in detections:\n",
    "            cls_id = int(cls_id)\n",
    "            cls_name = model.names[cls_id] if cls_id < len(model.names) else f\"Class {cls_id}\"\n",
    "            \n",
    "            # Check if this is a license plate detection\n",
    "            if 'plate' in str(cls_name).lower():\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                plates.append({\n",
    "                    'class': cls_name,\n",
    "                    'confidence': float(conf),\n",
    "                    'bbox': (x1, y1, x2, y2)\n",
    "                })\n",
    "                \n",
    "                # Annotate the original image\n",
    "                label = f\"{cls_name} {float(conf):.2f}\"\n",
    "                annotator_original.box_label(xyxy, label, colors(cls_id, True))\n",
    "    \n",
    "    # If no license plates found, return early\n",
    "    if not plates:\n",
    "        print(\"No license plates detected in first stage.\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'original_img': original_img,\n",
    "            'result_img': annotator_original.result(),\n",
    "            'license_info': {'emirate': 'Unknown', 'category': 'Unknown', 'plate_number': 'Unknown'}\n",
    "        }\n",
    "    \n",
    "    # Sort plates by confidence and take the highest one\n",
    "    plates.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    plate = plates[0]\n",
    "    print(f\"Found license plate with confidence {plate['confidence']:.2f}\")\n",
    "    \n",
    "    # Stage 2: Extract the license plate (simple crop with margin)\n",
    "    print(\"Stage 2: Extracting license plate...\")\n",
    "    \n",
    "    # Extract plate region with some margin\n",
    "    x1, y1, x2, y2 = plate['bbox']\n",
    "    h, w = y2 - y1, x2 - x1\n",
    "    \n",
    "    # Add margins (20% on each side)\n",
    "    margin_x = int(w * 0.20)\n",
    "    margin_y = int(h * 0.20)\n",
    "    \n",
    "    # Ensure margins don't go out of bounds\n",
    "    x1_margin = max(0, x1 - margin_x)\n",
    "    y1_margin = max(0, y1 - margin_y)\n",
    "    x2_margin = min(original_img.shape[1], x2 + margin_x)\n",
    "    y2_margin = min(original_img.shape[0], y2 + margin_y)\n",
    "    \n",
    "    # Crop the plate region\n",
    "    plate_img = original_img[y1_margin:y2_margin, x1_margin:x2_margin]\n",
    "    \n",
    "    # Stage 3: Run detection on the extracted plate\n",
    "    print(\"Stage 3: Detecting text on extracted plate...\")\n",
    "    \n",
    "    # Create a temporary file for the plate image\n",
    "    plate_detections = []\n",
    "    annotated_plate_img = None\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:\n",
    "        temp_path = tmp_file.name\n",
    "        cv2.imwrite(temp_path, plate_img)\n",
    "    \n",
    "    try:\n",
    "        # Run detection on the plate image\n",
    "        plate_dataset = LoadImages(temp_path, img_size=img_size)\n",
    "        \n",
    "        for _, plate_tensor, plate_img_original, _, _ in plate_dataset:\n",
    "            plate_tensor = torch.tensor(plate_tensor).to(model.device).float() / 255.0\n",
    "            if plate_tensor.ndimension() == 3:\n",
    "                plate_tensor = plate_tensor.unsqueeze(0)\n",
    "            \n",
    "            # Run model on the plate image with slightly lower confidence threshold\n",
    "            plate_pred = non_max_suppression(model(plate_tensor), conf_threshold * 0.7, iou_threshold)\n",
    "            \n",
    "            # Annotator for plate image\n",
    "            annotator_plate = Annotator(plate_img_original.copy())\n",
    "            \n",
    "            if plate_pred[0] is not None and len(plate_pred[0]) > 0:\n",
    "                plate_det = plate_pred[0]\n",
    "                plate_det[:, :4] = scale_boxes(plate_tensor.shape[2:], plate_det[:, :4], plate_img_original.shape).round()\n",
    "                \n",
    "                for *xyxy, conf, cls_id in plate_det:\n",
    "                    cls_id = int(cls_id)\n",
    "                    cls_name = model.names[cls_id] if cls_id < len(model.names) else f\"Class {cls_id}\"\n",
    "                    confidence = float(conf)\n",
    "                    bbox = [int(x) for x in xyxy]\n",
    "                    \n",
    "                    # Skip 'plate' class in the second pass - we only want the characters\n",
    "                    if 'plate' in str(cls_name).lower():\n",
    "                        continue\n",
    "                    \n",
    "                    plate_detections.append({\n",
    "                        'class': cls_name,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': bbox\n",
    "                    })\n",
    "                    \n",
    "                    # Annotate the plate image\n",
    "                    label = f\"{cls_name} {confidence:.2f}\"\n",
    "                    annotator_plate.box_label(xyxy, label, colors(cls_id, True))\n",
    "            \n",
    "            # Get the annotated plate image\n",
    "            annotated_plate_img = annotator_plate.result()\n",
    "            break  # Only process the first image\n",
    "            \n",
    "    finally:\n",
    "        # Clean up the temporary file\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "    \n",
    "    # Extract license info from the plate detections\n",
    "    license_info = extract_license_info(plate_detections)\n",
    "    \n",
    "    # Prepare the final annotated original image with license info\n",
    "    final_img = annotator_original.result()\n",
    "    \n",
    "    # Add license info text to the original image\n",
    "    cv2.putText(final_img, f\"Emirate: {license_info['emirate']}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(final_img, f\"Category: {license_info['category']}\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(final_img, f\"Plate Number: {license_info['plate_number']}\", (10, 90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    print(f\"Detection complete! Found: {license_info}\")\n",
    "    \n",
    "    return {\n",
    "        'success': True,\n",
    "        'original_img': original_img,\n",
    "        'result_img': final_img,\n",
    "        'plate_img': plate_img,  # Cropped plate without annotations\n",
    "        'annotated_plate_img': annotated_plate_img,  # Annotated plate\n",
    "        'license_info': license_info,\n",
    "        'plate_detections': plate_detections\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a659605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_two_stage_batch(model, test_dir, num_images=5, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"Process multiple images using two-stage detection\"\"\"\n",
    "    # Get list of image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(list(Path(test_dir).glob(f'*{ext}')))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {test_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Select random images or all if fewer than requested\n",
    "    import random\n",
    "    if len(image_files) > num_images:\n",
    "        selected_images = random.sample(image_files, num_images)\n",
    "    else:\n",
    "        selected_images = image_files\n",
    "    \n",
    "    print(f\"Processing {len(selected_images)} images using two-stage detection...\")\n",
    "    \n",
    "    # Process each image\n",
    "    results = []\n",
    "    for img_path in selected_images:\n",
    "        print(f\"\\nProcessing image: {img_path.name}\")\n",
    "        result = process_two_stage_detection(str(img_path), model, conf_threshold, iou_threshold)\n",
    "        \n",
    "        if result is None:\n",
    "            print(f\"Failed to process image: {img_path.name}\")\n",
    "            continue\n",
    "            \n",
    "        results.append(result)\n",
    "        \n",
    "        # Display results\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "        \n",
    "        # Original image\n",
    "        orig_img_rgb = cv2.cvtColor(result['original_img'], cv2.COLOR_BGR2RGB)\n",
    "        axs[0].imshow(orig_img_rgb)\n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "        # Annotated original image\n",
    "        result_img_rgb = cv2.cvtColor(result['result_img'], cv2.COLOR_BGR2RGB)\n",
    "        axs[1].imshow(result_img_rgb)\n",
    "        axs[1].set_title(\"Detected License Plate\")\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        # Cropped and annotated plate\n",
    "        if result['success'] and 'annotated_plate_img' in result and result['annotated_plate_img'] is not None:\n",
    "            plate_img_rgb = cv2.cvtColor(result['annotated_plate_img'], cv2.COLOR_BGR2RGB)\n",
    "            axs[2].imshow(plate_img_rgb)\n",
    "            axs[2].set_title(\"Cropped Plate with Detections\")\n",
    "        else:\n",
    "            # If plate extraction failed, show a blank panel\n",
    "            axs[2].imshow(np.ones((100, 200, 3), dtype=np.uint8) * 200)\n",
    "            axs[2].set_title(\"Plate Extraction Failed\")\n",
    "        axs[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"License Plate: {img_path.name}\", fontsize=16)\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "        \n",
    "        # Display extracted license info\n",
    "        license_info = result['license_info']\n",
    "        print(\"License Plate Information:\")\n",
    "        print(f\"Emirate: {license_info['emirate']}\")\n",
    "        print(f\"Category: {license_info['category']}\")\n",
    "        print(f\"License Number: {license_info['plate_number']}\")\n",
    "        \n",
    "        # Display detection details for second stage\n",
    "        if result['success'] and result['plate_detections']:\n",
    "            print(\"\\nPlate Detection Details:\")\n",
    "            print(f\"{'Class':<15} {'Confidence':<10} {'Bounding Box (x1,y1,x2,y2)'}\")\n",
    "            print(\"-\" * 60)\n",
    "            for det in result['plate_detections']:\n",
    "                cls = det['class']\n",
    "                conf = det['confidence']\n",
    "                bbox = det['bbox']\n",
    "                print(f\"{cls:<15} {conf:.2f}       ({bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]})\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a45643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_two_stage_results(result):\n",
    "    \"\"\"Display the results of two-stage license plate detection\"\"\"\n",
    "    if not result['success']:\n",
    "        # Show original image with message that no license plate was detected\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(result['result_img'], cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"No license plate detected\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    # Create a figure with 2 rows and 2 columns\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Original image\n",
    "    axs[0, 0].imshow(cv2.cvtColor(result['original_img'], cv2.COLOR_BGR2RGB))\n",
    "    axs[0, 0].set_title(\"Original Image\")\n",
    "    axs[0, 0].axis('off')\n",
    "\n",
    "    # Annotated original image\n",
    "    axs[0, 1].imshow(cv2.cvtColor(result['result_img'], cv2.COLOR_BGR2RGB))\n",
    "    axs[0, 1].set_title(\"Stage 1: License Plate Detection\")\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    # Extracted plate image\n",
    "    axs[1, 0].imshow(cv2.cvtColor(result['plate_img'], cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 0].set_title(\"Stage 2: Extracted Plate\")\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    # Annotated plate image\n",
    "    axs[1, 1].imshow(cv2.cvtColor(result['annotated_plate_img'], cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 1].set_title(\"Stage 3: Text Detection on Plate\")\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Two-Stage License Plate Detection\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Print license information\n",
    "    license_info = result['license_info']\n",
    "    print(\"License Plate Information:\")\n",
    "    print(f\"Emirate: {license_info['emirate']}\")\n",
    "    print(f\"Category: {license_info['category']}\")\n",
    "    print(f\"License Number: {license_info['plate_number']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b111bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(image_path, model):\n",
    "    \"\"\"Compare single-stage vs two-stage detection on the same image\"\"\"\n",
    "    print(f\"Processing image: {Path(image_path).name}\")\n",
    "\n",
    "    # Run single-stage detection\n",
    "    print(\"\\n===== SINGLE STAGE DETECTION =====\")\n",
    "    single_result = process_license_plate_image(image_path, model)\n",
    "\n",
    "    # Run two-stage detection\n",
    "    print(\"\\n===== TWO STAGE DETECTION =====\")\n",
    "    two_stage_result = process_two_stage_detection(image_path, model)\n",
    "\n",
    "    # Display single-stage results\n",
    "    print(\"\\nSingle-stage detection results:\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Original image\n",
    "    orig_img_rgb = cv2.cvtColor(single_result['original_img'], cv2.COLOR_BGR2RGB)\n",
    "    ax1.imshow(orig_img_rgb)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Annotated image with detections\n",
    "    result_img_rgb = cv2.cvtColor(single_result['result_img'], cv2.COLOR_BGR2RGB)\n",
    "    ax2.imshow(result_img_rgb)\n",
    "    ax2.set_title(\"Single-Stage Detection\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"License Plate: {Path(image_path).name} (Single-Stage)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Print single-stage license info\n",
    "    license_info_single = single_result['license_info']\n",
    "    print(\"License Plate Information (Single-Stage):\")\n",
    "    print(f\"Emirate: {license_info_single['emirate']}\")\n",
    "    print(f\"Category: {license_info_single['category']}\")\n",
    "    print(f\"License Number: {license_info_single['plate_number']}\")\n",
    "\n",
    "    # Display two-stage results\n",
    "    print(\"\\nTwo-stage detection results:\")\n",
    "    display_two_stage_results(two_stage_result)\n",
    "\n",
    "    # Return both results for comparison\n",
    "    return {\n",
    "        'single_stage': single_result,\n",
    "        'two_stage': two_stage_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeca7ae",
   "metadata": {},
   "source": [
    "## Load the YOLOv9 Model\n",
    "\n",
    "Now that we've defined all our functions, let's load the model and test the license plate detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4760905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path exists: False\n",
      "Test directory exists: False\n",
      "Loading model from /Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9/runs/train/gelan-c2/weights/best.pt\n",
      "Error loading model: [Errno 2] No such file or directory: '/Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9/runs/train/gelan-c2/weights/best.pt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/wn/m2rhf88j6b54x678vc1821200000gn/T/ipykernel_27618/1698736148.py\", line 12, in <module>\n",
      "    model = DetectMultiBackend(weights_path)\n",
      "  File \"/Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9/models/common.py\", line 705, in __init__\n",
      "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
      "  File \"/Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9/models/experimental.py\", line 243, in attempt_load\n",
      "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "  File \"/Users/zg0ul/miniconda3/envs/ai_cv_conda/lib/python3.10/site-packages/torch/serialization.py\", line 1425, in load\n",
      "    with _open_file_like(f, \"rb\") as opened_file:\n",
      "  File \"/Users/zg0ul/miniconda3/envs/ai_cv_conda/lib/python3.10/site-packages/torch/serialization.py\", line 751, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/Users/zg0ul/miniconda3/envs/ai_cv_conda/lib/python3.10/site-packages/torch/serialization.py\", line 732, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/zg0ul/Coding/SAGER/dubai_license/src/yolov9/runs/train/gelan-c2/weights/best.pt'\n"
     ]
    }
   ],
   "source": [
    "# Set paths for the model and test data\n",
    "weights_path = os.path.join(yolov9_path, \"runs/train/gelan-c2/weights/best.pt\")\n",
    "test_dir = os.path.join(yolov9_path, \"data/plates_dataset/test/images\")\n",
    "\n",
    "# Check if paths exist\n",
    "print(f\"Model path exists: {os.path.exists(weights_path)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(test_dir)}\")\n",
    "\n",
    "try:\n",
    "    # Load the model\n",
    "    print(f\"Loading model from {weights_path}\")\n",
    "    model = DetectMultiBackend(weights_path)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc641d6f",
   "metadata": {},
   "source": [
    "## Test Two-Stage Detection\n",
    "\n",
    "Let's test the two-stage detection process on multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run two-stage detection on a batch of images\n",
    "batch_results = process_two_stage_batch(model, test_dir, num_images=3)\n",
    "\n",
    "if batch_results:\n",
    "    print(f\"Successfully processed {len(batch_results)} images with two-stage detection\")\n",
    "else:\n",
    "    print(\"No images were successfully processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73185e9",
   "metadata": {},
   "source": [
    "## Compare Detection Methods\n",
    "\n",
    "Let's compare the single-stage and two-stage detection methods on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45df90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional testing code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_cv_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
